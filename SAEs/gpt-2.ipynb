{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sparse_autoencoder import (\n",
    "    ActivationResamplerHyperparameters,\n",
    "    AutoencoderHyperparameters,\n",
    "    Hyperparameters,\n",
    "    LossHyperparameters,\n",
    "    Method,\n",
    "    OptimizerHyperparameters,\n",
    "    Parameter,\n",
    "    PipelineHyperparameters,\n",
    "    SourceDataHyperparameters,\n",
    "    SourceModelHyperparameters,\n",
    "    SweepConfig,\n",
    "    sweep,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!source ../.env\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"gpt-2.ipynb\"\n",
    "def train_gpt_small_mlp_layers(\n",
    "    expansion_factor: int = 4,\n",
    "    layer: int = 6,\n",
    ") -> None:\n",
    "    \"\"\"Run a new sweep experiment on GPT 2 Small's MLP layers.\n",
    "\n",
    "    Args:\n",
    "        expansion_factor: Expansion factor for the autoencoder.\n",
    "        n_layers: Number of layers to train on. Max is 12.\n",
    "\n",
    "    \"\"\"\n",
    "    sweep_config = SweepConfig(\n",
    "        parameters=Hyperparameters(\n",
    "            loss=LossHyperparameters(\n",
    "                l1_coefficient=Parameter(max=0.03, min=0.008),\n",
    "            ),\n",
    "            optimizer=OptimizerHyperparameters(\n",
    "                lr=Parameter(max=0.001, min=0.00001),\n",
    "            ),\n",
    "            source_model=SourceModelHyperparameters(\n",
    "                name=Parameter(\"gpt2\"),\n",
    "                cache_names=Parameter(\n",
    "                    [f\"blocks.{layer}.hook_mlp_out\"]\n",
    "                ),\n",
    "                hook_dimension=Parameter(768),\n",
    "            ),\n",
    "            source_data=SourceDataHyperparameters(\n",
    "                dataset_path=Parameter(\"alancooney/sae-monology-pile-uncopyrighted-tokenizer-gpt2\"),\n",
    "                context_size=Parameter(256),\n",
    "                pre_tokenized=Parameter(value=True),\n",
    "                pre_download=Parameter(value=False),  # Default to streaming the dataset\n",
    "            ),\n",
    "            autoencoder=AutoencoderHyperparameters(\n",
    "                expansion_factor=Parameter(value=expansion_factor)\n",
    "            ),\n",
    "            pipeline=PipelineHyperparameters(\n",
    "                max_activations=Parameter(1_000_000_000),\n",
    "                checkpoint_frequency=Parameter(100_000_000),\n",
    "                validation_frequency=Parameter(100_000_000),\n",
    "                max_store_size=Parameter(1_000_000),\n",
    "            ),\n",
    "            activation_resampler=ActivationResamplerHyperparameters(\n",
    "                resample_interval=Parameter(200_000_000),\n",
    "                n_activations_activity_collate=Parameter(100_000_000),\n",
    "                threshold_is_dead_portion_fires=Parameter(1e-6),\n",
    "                max_n_resamples=Parameter(4),\n",
    "            ),\n",
    "        ),\n",
    "        method=Method.RANDOM,\n",
    "    )\n",
    "\n",
    "    sweep(sweep_config=sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: uzdfnotv\n",
      "Sweep URL: https://wandb.ai/shahrad_m/sparse-autoencoder/sweeps/uzdfnotv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e2xzdoaj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_resampler: {'max_n_resamples': 4, 'n_activations_activity_collate': 100000000, 'resample_dataset_size': 819200, 'resample_interval': 200000000, 'threshold_is_dead_portion_fires': 1e-06}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tautoencoder: {'expansion_factor': 4}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: {'l1_coefficient': 0.01862974667157214}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: {'adam_beta_1': 0.9, 'adam_beta_2': 0.99, 'adam_weight_decay': 0, 'amsgrad': False, 'fused': False, 'lr': 0.0001223696999119536}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpipeline: {'checkpoint_frequency': 100000000, 'log_frequency': 100, 'max_activations': 1000000000, 'max_store_size': 1000000, 'num_workers_data_loading': 0, 'source_data_batch_size': 16, 'train_batch_size': 8192, 'validation_frequency': 100000000, 'validation_n_activations': 8192}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trandom_seed: 49\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsource_data: {'context_size': 256, 'dataset_column_name': 'input_ids', 'dataset_path': 'alancooney/sae-monology-pile-uncopyrighted-tokenizer-gpt2', 'pre_download': False, 'pre_tokenized': True}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsource_model: {'cache_names': ['blocks.6.hook_mlp_out'], 'dtype': 'float32', 'hook_dimension': 768, 'name': 'gpt2'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mila/s/shahrad.mohammadzadeh/projects/pythia-hallucination/SAEs/wandb/run-20240627_113038-e2xzdoaj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shahrad_m/sparse-autoencoder/runs/e2xzdoaj' target=\"_blank\">silver-sweep-1</a></strong> to <a href='https://wandb.ai/shahrad_m/sparse-autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/shahrad_m/sparse-autoencoder/sweeps/uzdfnotv' target=\"_blank\">https://wandb.ai/shahrad_m/sparse-autoencoder/sweeps/uzdfnotv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shahrad_m/sparse-autoencoder' target=\"_blank\">https://wandb.ai/shahrad_m/sparse-autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/shahrad_m/sparse-autoencoder/sweeps/uzdfnotv' target=\"_blank\">https://wandb.ai/shahrad_m/sparse-autoencoder/sweeps/uzdfnotv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shahrad_m/sparse-autoencoder/runs/e2xzdoaj' target=\"_blank\">https://wandb.ai/shahrad_m/sparse-autoencoder/runs/e2xzdoaj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/shahrad.mohammadzadeh/projects/pythia-hallucination/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Activations trained on:   1%|          | 6995968/1000000000 [22:36<57:33:25, 4792.36it/s, stage=train]     \u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/learned_activations_l0_norm</td><td>█▃▂▂▁▁▁▁</td></tr><tr><td>train/learned_neuron_activity/alive_over_8192_activations</td><td>█▃▁▃▇▆▆▄</td></tr><tr><td>train/learned_neuron_activity/alive_over_98304_activations</td><td>▁█</td></tr><tr><td>train/learned_neuron_activity/almost_dead_1.0e-05_over_8192_activations</td><td>▁▆█▆▂▃▃▅</td></tr><tr><td>train/learned_neuron_activity/almost_dead_1.0e-05_over_98304_activations</td><td>█▁</td></tr><tr><td>train/learned_neuron_activity/almost_dead_1.0e-06_over_8192_activations</td><td>▁▆█▆▂▃▃▅</td></tr><tr><td>train/learned_neuron_activity/almost_dead_1.0e-06_over_98304_activations</td><td>█▁</td></tr><tr><td>train/learned_neuron_activity/dead_over_8192_activations</td><td>▁▆█▆▂▃▃▅</td></tr><tr><td>train/learned_neuron_activity/dead_over_98304_activations</td><td>█▁</td></tr><tr><td>train/loss/l2_reconstruction_loss</td><td>▆█▆▅▅▅▅▁</td></tr><tr><td>train/loss/learned_activations_l1</td><td>▅▁▁▂▂▄▇█</td></tr><tr><td>train/loss/learned_activations_l1_loss_penalty</td><td>▅▁▁▂▂▄▇█</td></tr><tr><td>train/loss/total_loss</td><td>▆█▆▄▄▅▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/learned_activations_l0_norm</td><td>1.81958</td></tr><tr><td>train/learned_neuron_activity/alive_over_8192_activations</td><td>2653</td></tr><tr><td>train/learned_neuron_activity/alive_over_98304_activations</td><td>3072</td></tr><tr><td>train/learned_neuron_activity/almost_dead_1.0e-05_over_8192_activations</td><td>419</td></tr><tr><td>train/learned_neuron_activity/almost_dead_1.0e-05_over_98304_activations</td><td>0</td></tr><tr><td>train/learned_neuron_activity/almost_dead_1.0e-06_over_8192_activations</td><td>419</td></tr><tr><td>train/learned_neuron_activity/almost_dead_1.0e-06_over_98304_activations</td><td>0</td></tr><tr><td>train/learned_neuron_activity/dead_over_8192_activations</td><td>419</td></tr><tr><td>train/learned_neuron_activity/dead_over_98304_activations</td><td>0</td></tr><tr><td>train/loss/l2_reconstruction_loss</td><td>0.53828</td></tr><tr><td>train/loss/learned_activations_l1</td><td>0.18563</td></tr><tr><td>train/loss/learned_activations_l1_loss_penalty</td><td>0.00346</td></tr><tr><td>train/loss/total_loss</td><td>0.54174</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sweep-1</strong> at: <a href='https://wandb.ai/shahrad_m/sparse-autoencoder/runs/e2xzdoaj' target=\"_blank\">https://wandb.ai/shahrad_m/sparse-autoencoder/runs/e2xzdoaj</a><br/> View project at: <a href='https://wandb.ai/shahrad_m/sparse-autoencoder' target=\"_blank\">https://wandb.ai/shahrad_m/sparse-autoencoder</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240627_113038-e2xzdoaj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_gpt_small_mlp_layers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
